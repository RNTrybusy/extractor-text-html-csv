import os
from bs4 import BeautifulSoup
import pandas as pd

# Script para extrair palavras japonesas de arquivos HTML exportados do Telegram
# Objetivo: Converter mensagens de conversas de aprendizado de japonÃªs em uma planilha CSV estruturada

# Lista de arquivos HTML de origem que contÃªm as mensagens
file_paths = ["messages.html", "messages2.html"]

# Lista para armazenar os dados extraÃ­dos
data = []

# Itera sobre cada arquivo HTML na lista
for file_path in file_paths:
    # Verifica se o arquivo existe
    if not os.path.exists(file_path):
        print(f"Arquivo nÃ£o encontrado: {file_path}")
        continue

    # Abre e analisa o arquivo HTML
    with open(file_path, 'r', encoding='utf-8') as file:
        # Usa BeautifulSoup para parsear o HTML
        soup = BeautifulSoup(file, 'html.parser')
        
        # Encontra todas as divs com classe "text" que contÃªm as mensagens
        for div in soup.find_all("div", class_="text"):
            # ObtÃ©m o texto da div, removendo espaÃ§os extras
            text = div.get_text(strip=True)
            
            # Verifica se a mensagem contÃ©m bandeiras do JapÃ£o e Brasil (formato especÃ­fico)
            if "ğŸ‡¯ğŸ‡µ" in text and "ğŸ‡§ğŸ‡·" in text:
                # Divide o texto usando as bandeiras como separadores
                parts = text.split("ğŸ‡¯ğŸ‡µ")[1].split("ğŸ‡§ğŸ‡·")
                jp_part = parts[0].strip()
                pt_part = parts[1].strip()
                
                # Extrai palavra, leitura e traduÃ§Ã£o
                # Formato esperado: Palavra ã€Leituraã€‘ ğŸ‡§ğŸ‡· TraduÃ§Ã£o
                if "ã€" in jp_part and "ã€‘" in jp_part:
                    word, reading = jp_part.split("ã€")
                    reading = reading.strip("ã€‘")
                    
                    # Adiciona os dados extraÃ­dos Ã  lista
                    data.append({
                        "word": word.strip(), 
                        "reading": reading.strip(), 
                        "translation-pt-br": pt_part, 
                        "jlpt": "N5"  # NÃ­vel JLPT padrÃ£o (pode ser ajustado)
                    })

# Cria um DataFrame do pandas com os dados extraÃ­dos
df = pd.DataFrame(data)

# Adiciona uma coluna de ID sequencial
df.insert(0, 'id', range(1, len(df) + 1))

# Define o diretÃ³rio de saÃ­da para o arquivo CSV
output_dir = "\data"

# Cria o diretÃ³rio de saÃ­da se nÃ£o existir
os.makedirs(output_dir, exist_ok=True)

# Caminho completo para o arquivo CSV
output_path = os.path.join(output_dir, "word_list.csv")

# Salva o DataFrame como um arquivo CSV
df.to_csv(output_path, index=False)

# Mensagens de confirmaÃ§Ã£o
print(f"Palavras salvas em {output_path}")
print(f"Total de palavras extraÃ­das: {len(df)}")